{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.rendered_html { font-size: 18px; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.rendered_html { font-size: 18px; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First initial libraries. Machine learning has been left out for now.\n",
    "\n",
    "Additionally, the datasets are much too large for my laptops memory, so I will load truncated versions. I will also keep a commented-out cell which attempts to either load the whole dataset, or use a SQL server for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data analysis and wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "import nltk\n",
    "import datetime\n",
    "import math\n",
    "#from sqlalchemy import create_engine\n",
    "#nltk.download()\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first cell here will upload smaller sections of the datasets. We will go in a roundabout way in order to upload datafiles to github. Which will be commented out once used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#csv_2016 = pd.read_csv('properties_2016.csv', nrows = 30000)\n",
    "#csv_2017 = pd.read_csv('properties_2017.csv', nrows = 30000)\n",
    "#csv_2016.to_csv('2016.csv')\n",
    "#csv_2017.to_csv('2017.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "raw_2016 = pd.read_csv('2016.csv')\n",
    "raw_2017 = pd.read_csv('2017.csv')\n",
    "vals_2016 = pd.read_csv('train_2016_v2.csv')\n",
    "vals_2017 = pd.read_csv('train_2017.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell will load the entire datasets, and I will likely not ever be able to use this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_2016 = pd.read_csv('properties_2016.csv', low_memory = False)\n",
    "#raw_2017 = pd.read_csv('properties_2017.csv', low_memory = False)\n",
    "#vals_2016 = pd.read_csv('train_2016_v2.csv')\n",
    "#vals_2017 = pd.read_csv('train_2017.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally a third possible solution that lets me use SQL to pull in large datasets after I have figured out how to trim the dataset.\n",
    "\n",
    "This still has big memory issues, so it may not end up being used either. I would also like to know if there is a way to minimize a cell as this the SQL cell takes up a lot of room."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "vals_2016 = pd.read_csv('train_2016_v2.csv')\n",
    "vals_2017 = pd.read_csv('train_2017.csv')\n",
    "\n",
    "csv_database = create_engine('sqlite:///csv_database.db')\n",
    "\n",
    "# Next we load a the 2016 dataset into a SQL engine table chunk by chunk\n",
    "chunksize = 10000\n",
    "i_1 = 0\n",
    "j_1 = 1\n",
    "for df in pd.read_csv('properties_2016.csv', chunksize=chunksize, iterator=True):\n",
    "      df = df.rename(columns={c: c.replace(' ', '') for c in df.columns}) \n",
    "      df.index += j_1\n",
    "      i_1+=1\n",
    "      df.to_sql('table_2016', csv_database, if_exists='append')\n",
    "      j = df.index[-1] + 1\n",
    "#now we do the same for 2017 into another table\n",
    "i_2 = 0\n",
    "j_2 = 1\n",
    "for df in pd.read_csv('properties_2017.csv', chunksize=chunksize, iterator=True):\n",
    "      df = df.rename(columns={c: c.replace(' ', '') for c in df.columns}) \n",
    "      df.index += j_2\n",
    "      i_2+=1\n",
    "      df.to_sql('table_2017', csv_database, if_exists='append')\n",
    "      j = df.index[-1] + 1\n",
    "        \n",
    "df = pd.read_sql_query('SELECT COl1 table_2017', csv_database)\n",
    "df.head()\n",
    "'''\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can merge the dataframes with their vals we need to see how long each are. We note that there are far more in the vals dataframe, but since we did not truncate those csv files but did for the raw files, we do not know if vals is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 90275)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_2016),len(vals_2016)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will merge the raw df with the vals df. However, we note that the df's when merged on 'inner' are MUCH smaller than the starting ones, meaning that the train csv's were smaller than the raw csv's. However, since this notebook is primary concerned with munging and cleaning, we will proceed anyway, hoping for a solution where we can deal with the larger datasets.\n",
    "\n",
    "Another important observation is that the mergeing process gained us two extra rows so we no longer have unique entries in parcelid. However, the vals dataframe (which was not truncated) has several repeated parcelid's meaning that the original dataset will have likely contained a great number of repeated parcelids. As such we will leave them be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "896\n",
      "30002 30000\n",
      "30003 30000\n",
      "90275 90150\n"
     ]
    }
   ],
   "source": [
    "df2016 = pd.merge(raw_2016, vals_2016, how='left', left_on='parcelid', right_on='parcelid')\n",
    "df2017 = pd.merge(raw_2017, vals_2017, how='left', left_on='parcelid', right_on='parcelid')\n",
    "print(len(pd.merge(raw_2016, vals_2016, how='inner', left_on='parcelid', right_on='parcelid')))\n",
    "print(len(df2016['parcelid']),len(df2016['parcelid'].unique()))\n",
    "print(len(df2017['parcelid']),len(df2017['parcelid'].unique()))\n",
    "print(len(vals_2016['parcelid']), len(vals_2016['parcelid'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets get some information on the structure of these dataframes as well as what types of data are inside it. The biggest observations we can make here is that there are many empty columns, likely resulting from the extreme truncation. As a result, we will need merge with how='left'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 896 entries, 0 to 895\n",
      "Data columns (total 61 columns):\n",
      "Unnamed: 0                      896 non-null int64\n",
      "parcelid                        896 non-null int64\n",
      "airconditioningtypeid           276 non-null float64\n",
      "architecturalstyletypeid        0 non-null float64\n",
      "basementsqft                    0 non-null float64\n",
      "bathroomcnt                     896 non-null float64\n",
      "bedroomcnt                      896 non-null float64\n",
      "buildingclasstypeid             0 non-null float64\n",
      "buildingqualitytypeid           551 non-null float64\n",
      "calculatedbathnbr               884 non-null float64\n",
      "decktypeid                      7 non-null float64\n",
      "finishedfloor1squarefeet        67 non-null float64\n",
      "calculatedfinishedsquarefeet    890 non-null float64\n",
      "finishedsquarefeet12            851 non-null float64\n",
      "finishedsquarefeet13            0 non-null float64\n",
      "finishedsquarefeet15            35 non-null float64\n",
      "finishedsquarefeet50            67 non-null float64\n",
      "finishedsquarefeet6             4 non-null float64\n",
      "fips                            896 non-null int64\n",
      "fireplacecnt                    97 non-null float64\n",
      "fullbathcnt                     884 non-null float64\n",
      "garagecarcnt                    314 non-null float64\n",
      "garagetotalsqft                 314 non-null float64\n",
      "hashottuborspa                  21 non-null object\n",
      "heatingorsystemtypeid           536 non-null float64\n",
      "latitude                        896 non-null int64\n",
      "longitude                       896 non-null int64\n",
      "lotsizesquarefeet               781 non-null float64\n",
      "poolcnt                         183 non-null float64\n",
      "poolsizesum                     9 non-null float64\n",
      "pooltypeid10                    7 non-null float64\n",
      "pooltypeid2                     14 non-null float64\n",
      "pooltypeid7                     169 non-null float64\n",
      "propertycountylandusecode       896 non-null object\n",
      "propertylandusetypeid           896 non-null int64\n",
      "propertyzoningdesc              564 non-null object\n",
      "rawcensustractandblock          896 non-null float64\n",
      "regionidcity                    876 non-null float64\n",
      "regionidcounty                  896 non-null int64\n",
      "regionidneighborhood            372 non-null float64\n",
      "regionidzip                     895 non-null float64\n",
      "roomcnt                         896 non-null float64\n",
      "storytypeid                     0 non-null float64\n",
      "threequarterbathnbr             136 non-null float64\n",
      "typeconstructiontypeid          0 non-null float64\n",
      "unitcnt                         560 non-null float64\n",
      "yardbuildingsqft17              26 non-null float64\n",
      "yardbuildingsqft26              0 non-null float64\n",
      "yearbuilt                       888 non-null float64\n",
      "numberofstories                 196 non-null float64\n",
      "fireplaceflag                   0 non-null object\n",
      "structuretaxvaluedollarcnt      892 non-null float64\n",
      "taxvaluedollarcnt               896 non-null float64\n",
      "assessmentyear                  896 non-null int64\n",
      "landtaxvaluedollarcnt           896 non-null float64\n",
      "taxamount                       896 non-null float64\n",
      "taxdelinquencyflag              13 non-null object\n",
      "taxdelinquencyyear              13 non-null float64\n",
      "censustractandblock             889 non-null float64\n",
      "logerror                        896 non-null float64\n",
      "transactiondate                 896 non-null object\n",
      "dtypes: float64(47), int64(8), object(6)\n",
      "memory usage: 434.0+ KB\n"
     ]
    }
   ],
   "source": [
    "pd.merge(raw_2016, vals_2016, how='inner', left_on='parcelid', right_on='parcelid').info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 30002 entries, 0 to 30001\n",
      "Data columns (total 61 columns):\n",
      "Unnamed: 0                      30002 non-null int64\n",
      "parcelid                        30002 non-null int64\n",
      "airconditioningtypeid           8087 non-null float64\n",
      "architecturalstyletypeid        70 non-null float64\n",
      "basementsqft                    16 non-null float64\n",
      "bathroomcnt                     30002 non-null float64\n",
      "bedroomcnt                      30002 non-null float64\n",
      "buildingclasstypeid             179 non-null float64\n",
      "buildingqualitytypeid           19323 non-null float64\n",
      "calculatedbathnbr               28530 non-null float64\n",
      "decktypeid                      172 non-null float64\n",
      "finishedfloor1squarefeet        2040 non-null float64\n",
      "calculatedfinishedsquarefeet    29474 non-null float64\n",
      "finishedsquarefeet12            27217 non-null float64\n",
      "finishedsquarefeet13            90 non-null float64\n",
      "finishedsquarefeet15            1953 non-null float64\n",
      "finishedsquarefeet50            2040 non-null float64\n",
      "finishedsquarefeet6             214 non-null float64\n",
      "fips                            30002 non-null int64\n",
      "fireplacecnt                    3114 non-null float64\n",
      "fullbathcnt                     28530 non-null float64\n",
      "garagecarcnt                    8889 non-null float64\n",
      "garagetotalsqft                 8889 non-null float64\n",
      "hashottuborspa                  694 non-null object\n",
      "heatingorsystemtypeid           17993 non-null float64\n",
      "latitude                        30002 non-null int64\n",
      "longitude                       30002 non-null int64\n",
      "lotsizesquarefeet               27105 non-null float64\n",
      "poolcnt                         5205 non-null float64\n",
      "poolsizesum                     248 non-null float64\n",
      "pooltypeid10                    364 non-null float64\n",
      "pooltypeid2                     330 non-null float64\n",
      "pooltypeid7                     4875 non-null float64\n",
      "propertycountylandusecode       29992 non-null object\n",
      "propertylandusetypeid           30002 non-null int64\n",
      "propertyzoningdesc              19801 non-null object\n",
      "rawcensustractandblock          30002 non-null float64\n",
      "regionidcity                    29486 non-null float64\n",
      "regionidcounty                  30002 non-null int64\n",
      "regionidneighborhood            11622 non-null float64\n",
      "regionidzip                     29974 non-null float64\n",
      "roomcnt                         30002 non-null float64\n",
      "storytypeid                     16 non-null float64\n",
      "threequarterbathnbr             3123 non-null float64\n",
      "typeconstructiontypeid          73 non-null float64\n",
      "unitcnt                         19718 non-null float64\n",
      "yardbuildingsqft17              828 non-null float64\n",
      "yardbuildingsqft26              21 non-null float64\n",
      "yearbuilt                       29424 non-null float64\n",
      "numberofstories                 6881 non-null float64\n",
      "fireplaceflag                   59 non-null object\n",
      "structuretaxvaluedollarcnt      29390 non-null float64\n",
      "taxvaluedollarcnt               29560 non-null float64\n",
      "assessmentyear                  30002 non-null int64\n",
      "landtaxvaluedollarcnt           29282 non-null float64\n",
      "taxamount                       29779 non-null float64\n",
      "taxdelinquencyflag              614 non-null object\n",
      "taxdelinquencyyear              614 non-null float64\n",
      "censustractandblock             29071 non-null float64\n",
      "logerror                        896 non-null float64\n",
      "transactiondate                 896 non-null object\n",
      "dtypes: float64(47), int64(8), object(6)\n",
      "memory usage: 14.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df2016.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we no longer have any empty columns. Unfortunately some are still almost empty. One goal to look into later will be to find a way to read a csv with n randomly selected rows to get a potentially more representative sample of the original dataset.\n",
    "\n",
    "We want to combine the 2016 and 2017 datasets and now we note that we have a great deal of repeated parcelid entries, so this new dataframe perhaps more closely resembles the larger datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30124 60005\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 60005 entries, 0 to 30002\n",
      "Data columns (total 61 columns):\n",
      "Unnamed: 0                      60005 non-null int64\n",
      "parcelid                        60005 non-null int64\n",
      "airconditioningtypeid           16222 non-null float64\n",
      "architecturalstyletypeid        140 non-null float64\n",
      "basementsqft                    31 non-null float64\n",
      "bathroomcnt                     60005 non-null float64\n",
      "bedroomcnt                      60005 non-null float64\n",
      "buildingclasstypeid             361 non-null float64\n",
      "buildingqualitytypeid           38701 non-null float64\n",
      "calculatedbathnbr               57178 non-null float64\n",
      "decktypeid                      350 non-null float64\n",
      "finishedfloor1squarefeet        4084 non-null float64\n",
      "calculatedfinishedsquarefeet    59014 non-null float64\n",
      "finishedsquarefeet12            54514 non-null float64\n",
      "finishedsquarefeet13            174 non-null float64\n",
      "finishedsquarefeet15            3904 non-null float64\n",
      "finishedsquarefeet50            4084 non-null float64\n",
      "finishedsquarefeet6             422 non-null float64\n",
      "fips                            60005 non-null int64\n",
      "fireplacecnt                    6230 non-null float64\n",
      "fullbathcnt                     57178 non-null float64\n",
      "garagecarcnt                    17839 non-null float64\n",
      "garagetotalsqft                 17839 non-null float64\n",
      "hashottuborspa                  1206 non-null object\n",
      "heatingorsystemtypeid           36626 non-null float64\n",
      "latitude                        60005 non-null int64\n",
      "longitude                       60005 non-null int64\n",
      "lotsizesquarefeet               54235 non-null float64\n",
      "poolcnt                         10615 non-null float64\n",
      "poolsizesum                     495 non-null float64\n",
      "pooltypeid10                    540 non-null float64\n",
      "pooltypeid2                     666 non-null float64\n",
      "pooltypeid7                     9941 non-null float64\n",
      "propertycountylandusecode       59995 non-null object\n",
      "propertylandusetypeid           60005 non-null int64\n",
      "propertyzoningdesc              39645 non-null object\n",
      "rawcensustractandblock          60005 non-null float64\n",
      "regionidcity                    58909 non-null float64\n",
      "regionidcounty                  60005 non-null int64\n",
      "regionidneighborhood            23239 non-null float64\n",
      "regionidzip                     59887 non-null float64\n",
      "roomcnt                         60005 non-null float64\n",
      "storytypeid                     31 non-null float64\n",
      "threequarterbathnbr             6296 non-null float64\n",
      "typeconstructiontypeid          146 non-null float64\n",
      "unitcnt                         39480 non-null float64\n",
      "yardbuildingsqft17              1660 non-null float64\n",
      "yardbuildingsqft26              42 non-null float64\n",
      "yearbuilt                       58938 non-null float64\n",
      "numberofstories                 13802 non-null float64\n",
      "fireplaceflag                   118 non-null object\n",
      "structuretaxvaluedollarcnt      58838 non-null float64\n",
      "taxvaluedollarcnt               59160 non-null float64\n",
      "assessmentyear                  60005 non-null int64\n",
      "landtaxvaluedollarcnt           58603 non-null float64\n",
      "taxamount                       59574 non-null float64\n",
      "taxdelinquencyflag              1229 non-null object\n",
      "taxdelinquencyyear              1229 non-null float64\n",
      "censustractandblock             58149 non-null float64\n",
      "logerror                        1691 non-null float64\n",
      "transactiondate                 1691 non-null object\n",
      "dtypes: float64(47), int64(8), object(6)\n",
      "memory usage: 28.4+ MB\n"
     ]
    }
   ],
   "source": [
    "combined_df = pd.concat([df2016,df2017]).copy()\n",
    "#combined_df.set_index('parcelid', inplace=True)\n",
    "print(len(combined_df['parcelid'].unique()),len(combined_df['parcelid']))\n",
    "combined_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nearly all our data is numberical and thus requires little cleaning in that respect. But we will take a closer look at the data fields which are non-numberical in case they require cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan True]\n",
      "['010D' '0109' '1200' '1210' '010V' '300V' '0100' '0200' '010C' '0300'\n",
      " '1204' '100V' '01HC' '120C' '040V' '1214' '0101' nan '070P' '0700' '1'\n",
      " '128' '0' '1112' '5050' '1110' '1118' '010E' '1111' '1129' '1420' '1222'\n",
      " '1128' '1310' '1117' '1333' '1116' '1410' '0104' '070D' '0108' '012C'\n",
      " '0400' '0103' '01DC' '0201' '010M' '030V' '0110' '010F' '010G' '010H'\n",
      " '0301' '0102' '020E' '020M' '0401' '0113' '0141' '122' '38' '135' '96'\n",
      " '71' '73' '34' '0209' '040G' '010L' '012E' '0111' '1720' '1014' '012D'\n",
      " '1213' '1201' '1321' '1444' '1421' '0140' '0123' '0133' '020G' '030G'\n",
      " '105' '0204' '010T' '0120' '1202' '121G' '010X' '020V' '880V' '01HE']\n",
      "[nan 'LCA11*' 'LAC2' ..., 'SCRM(PD)' 'LBPD13' 'WHM2*']\n",
      "[nan True]\n",
      "[nan 'Y']\n",
      "[nan '2016-01-27' '2016-03-30' '2016-05-27' '2016-06-07' '2016-08-08'\n",
      " '2016-08-26' '2016-07-08' '2016-05-11' '2016-06-15' '2016-10-07'\n",
      " '2016-05-20' '2016-03-17' '2016-05-18' '2016-04-13' '2016-07-06'\n",
      " '2016-12-29' '2016-01-11' '2016-09-07' '2016-05-23' '2016-07-15'\n",
      " '2016-05-19' '2016-06-13' '2016-08-24' '2016-10-14' '2016-07-01'\n",
      " '2016-10-03' '2016-03-01' '2016-03-31' '2016-06-27' '2016-04-15'\n",
      " '2016-02-25' '2016-06-14' '2016-09-28' '2016-04-12' '2016-08-12'\n",
      " '2016-09-19' '2016-11-16' '2016-04-07' '2016-11-23' '2016-01-08'\n",
      " '2016-06-29' '2016-10-28' '2016-05-09' '2016-11-14' '2016-06-02'\n",
      " '2016-01-15' '2016-04-06' '2016-01-13' '2016-07-07' '2016-06-16'\n",
      " '2016-01-20' '2016-01-05' '2016-01-28' '2016-02-01' '2016-04-19'\n",
      " '2016-06-20' '2016-07-29' '2016-10-06' '2016-05-17' '2016-05-13'\n",
      " '2016-07-28' '2016-06-17' '2016-06-30' '2016-09-06' '2016-08-30'\n",
      " '2016-03-21' '2016-04-26' '2016-04-29' '2016-07-22' '2016-06-28'\n",
      " '2016-04-08' '2016-09-30' '2016-01-14' '2016-08-01' '2016-06-22'\n",
      " '2016-09-16' '2016-03-25' '2016-07-19' '2016-01-29' '2016-03-16'\n",
      " '2016-05-06' '2016-09-23' '2016-08-29' '2016-08-22' '2016-03-24'\n",
      " '2016-08-19' '2016-05-10' '2016-03-04' '2016-05-25' '2016-02-08'\n",
      " '2016-04-18' '2016-05-26' '2016-02-07' '2016-05-12' '2016-10-12'\n",
      " '2016-07-27' '2016-08-15' '2016-05-24' '2016-06-01' '2016-04-01'\n",
      " '2016-09-20' '2016-08-16' '2016-07-21' '2016-05-03' '2016-03-23'\n",
      " '2016-10-20' '2016-08-04' '2016-06-23' '2016-04-21' '2016-10-13'\n",
      " '2016-04-28' '2016-01-22' '2016-03-29' '2016-06-06' '2016-04-04'\n",
      " '2016-01-25' '2016-06-03' '2016-02-22' '2016-04-27' '2016-08-09'\n",
      " '2016-06-08' '2016-04-05' '2016-08-10' '2016-12-30' '2016-12-06'\n",
      " '2016-07-11' '2016-08-05' '2016-09-26' '2016-09-02' '2016-09-09'\n",
      " '2016-02-29' '2016-12-14' '2016-03-10' '2016-01-06' '2016-10-04'\n",
      " '2016-07-05' '2016-06-10' '2016-02-18' '2016-07-12' '2016-01-31'\n",
      " '2016-05-02' '2016-01-21' '2016-08-11' '2016-12-23' '2016-02-03'\n",
      " '2016-10-05' '2016-09-15' '2016-09-22' '2016-11-13' '2016-08-18'\n",
      " '2016-07-20' '2016-07-26' '2016-12-26' '2016-02-17' '2016-01-07'\n",
      " '2016-05-31' '2016-11-28' '2016-05-04' '2016-02-16' '2016-03-28'\n",
      " '2016-08-31' '2016-07-25' '2016-06-09' '2016-07-14' '2016-01-12'\n",
      " '2016-02-26' '2016-03-07' '2016-08-02' '2016-09-14' '2016-03-15'\n",
      " '2016-11-12' '2016-09-29' '2016-10-27' '2016-02-21' '2016-12-15'\n",
      " '2016-01-04' '2016-03-09' '2016-03-08' '2016-10-21' '2016-08-17'\n",
      " '2016-06-24' '2016-02-12' '2016-03-18' '2016-04-14' '2016-12-21'\n",
      " '2016-11-08' '2016-07-13' '2016-02-04' '2016-04-20' '2016-03-11'\n",
      " '2016-02-19' '2016-04-22' '2016-12-07' '2016-02-24' '2016-12-09'\n",
      " '2016-10-11' '2016-03-22' '2016-11-09' '2016-02-11' '2016-06-21'\n",
      " '2016-08-25' '2016-11-22' '2016-02-10' '2016-05-16' '2016-11-15'\n",
      " '2016-11-17' '2016-09-01' '2016-03-02' '2016-01-26' '2016-11-01'\n",
      " '2016-03-06' '2016-03-14' '2016-07-18' '2016-10-18' '2016-08-03'\n",
      " '2016-08-23' '2016-04-11' '2016-09-08' '2016-05-05' '2016-01-18'\n",
      " '2016-04-25' '2016-10-19' '2016-12-28' '2017-06-15' '2017-07-26'\n",
      " '2017-07-28' '2017-06-02' '2017-07-07' '2017-04-12' '2017-01-30'\n",
      " '2017-04-19' '2017-09-08' '2017-04-28' '2017-03-31' '2017-07-06'\n",
      " '2017-05-12' '2017-08-03' '2017-03-07' '2017-01-03' '2017-04-07'\n",
      " '2017-05-24' '2017-05-26' '2017-04-10' '2017-06-12' '2017-08-24'\n",
      " '2017-06-08' '2017-08-30' '2017-05-19' '2017-07-25' '2017-08-08'\n",
      " '2017-02-13' '2017-03-09' '2017-07-10' '2017-07-27' '2017-08-01'\n",
      " '2017-09-18' '2017-03-10' '2017-05-31' '2017-07-05' '2017-02-23'\n",
      " '2017-04-04' '2017-03-20' '2017-05-25' '2017-02-21' '2017-07-31'\n",
      " '2017-05-11' '2017-09-01' '2017-02-17' '2017-09-06' '2017-09-15'\n",
      " '2017-01-26' '2017-03-14' '2017-06-06' '2017-01-12' '2017-04-21'\n",
      " '2017-06-27' '2017-06-30' '2017-06-29' '2017-08-04' '2017-04-03'\n",
      " '2017-08-14' '2017-09-11' '2017-08-07' '2017-03-29' '2017-09-07'\n",
      " '2017-02-07' '2017-08-25' '2017-02-28' '2017-04-18' '2017-05-05'\n",
      " '2017-08-23' '2017-05-17' '2017-09-19' '2017-08-10' '2017-06-09'\n",
      " '2017-01-23' '2017-05-01' '2017-02-22' '2017-03-06' '2017-01-11'\n",
      " '2017-03-01' '2017-06-20' '2017-05-08' '2017-01-19' '2017-06-01'\n",
      " '2017-04-26' '2017-06-23' '2017-05-02' '2017-06-13' '2017-04-14'\n",
      " '2017-03-17' '2017-02-15' '2017-05-10' '2017-06-07' '2017-04-25'\n",
      " '2017-08-31' '2017-02-06' '2017-04-20' '2017-06-14' '2017-06-22'\n",
      " '2017-03-13' '2017-01-29' '2017-03-02' '2017-07-19' '2017-08-17'\n",
      " '2017-03-16' '2017-03-21' '2017-07-14' '2017-04-24' '2017-08-27'\n",
      " '2017-02-01' '2017-08-18' '2017-01-24' '2017-06-16' '2017-03-28'\n",
      " '2017-07-03' '2017-05-15' '2017-08-09' '2017-09-13' '2017-05-03'\n",
      " '2017-09-14' '2017-04-06' '2017-08-16' '2017-01-13' '2017-02-03'\n",
      " '2017-04-11' '2017-03-30' '2017-03-15' '2017-01-06' '2017-08-11'\n",
      " '2017-04-13' '2017-05-04' '2017-02-14' '2017-07-13' '2017-06-21'\n",
      " '2017-03-08' '2017-05-23' '2017-08-21' '2017-01-31' '2017-05-21'\n",
      " '2017-03-24' '2017-01-17' '2017-02-09' '2017-01-01' '2017-03-27'\n",
      " '2017-02-24' '2017-07-12' '2017-05-30' '2017-05-22' '2017-02-10'\n",
      " '2017-02-16' '2017-04-05' '2017-06-26' '2017-07-18' '2017-05-16'\n",
      " '2017-05-18' '2017-01-25' '2017-03-23' '2017-02-26' '2017-08-22'\n",
      " '2017-05-09' '2017-07-17' '2017-01-05' '2017-01-02' '2017-09-12'\n",
      " '2017-02-20' '2017-09-05' '2017-03-22' '2017-08-29' '2017-02-02'\n",
      " '2017-02-08' '2017-07-21' '2017-02-12' '2017-01-04' '2017-07-24'\n",
      " '2017-08-15' '2017-04-27' '2017-01-16' '2017-02-27' '2017-01-10'\n",
      " '2017-01-20' '2017-06-19' '2017-06-28' '2017-07-20' '2017-07-11'\n",
      " '2017-04-02']\n"
     ]
    }
   ],
   "source": [
    "Object_columns = ['hashottuborspa', 'propertycountylandusecode','propertyzoningdesc',\n",
    "                  'fireplaceflag', 'taxdelinquencyflag','transactiondate']\n",
    "\n",
    "for column in Object_columns:\n",
    "    df = combined_df[column].unique()\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have some boolean, catagorical and datetime data. So lets see if the data is recorded as such."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{<class 'bool'>}\n",
      "{<class 'bool'>}\n",
      "{<class 'str'>}\n",
      "{<class 'str'>}\n"
     ]
    }
   ],
   "source": [
    "Object_columns_2 = ['hashottuborspa','fireplaceflag', 'taxdelinquencyflag','transactiondate']\n",
    "for column in Object_columns_2:\n",
    "    df = combined_df[column].dropna()\n",
    "    types = []\n",
    "    for entry in df:\n",
    "        types.append(type(entry))\n",
    "    print(set(types))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two boolean looking columns were in fact boolean. Additional taxdelinquencyflag, 'propertycountylandusecode' and 'propertyzoningdesc' are string based categorical. So we can turn those into int based catagorical.\n",
    "\n",
    "Finally, we will need to convert transactiondate into datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_intcat(df,col):\n",
    "    result = pd.factorize(df[col])[0]\n",
    "    return pd.Series((v for v in result))\n",
    "\n",
    "def bool_to_int(df,col):\n",
    "    result = []\n",
    "    for entry in df[col]:\n",
    "        if entry == 'Y' or entry == True:\n",
    "            result.append(1)\n",
    "        elif entry == 'N' or entry == False:\n",
    "            result.append(0)\n",
    "        else:\n",
    "            result.append(-1)\n",
    "    return pd.Series((v for v in result))\n",
    "\n",
    "def to_datetime(df,col):\n",
    "    result = []\n",
    "    for entry in df[col]:\n",
    "        if pd.isnull(entry) == True:\n",
    "            result.append(entry)\n",
    "        else:\n",
    "            result.append(pd.Timestamp(entry))\n",
    "    return pd.Series((v for v in result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will replace the data in combined_df with the new data. \n",
    "['hashottuborspa', 'propertycountylandusecode','propertyzoningdesc',\n",
    "                  'fireplaceflag', 'taxdelinquencyflag','transactiondate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>parcelid</th>\n",
       "      <th>airconditioningtypeid</th>\n",
       "      <th>architecturalstyletypeid</th>\n",
       "      <th>basementsqft</th>\n",
       "      <th>bathroomcnt</th>\n",
       "      <th>bedroomcnt</th>\n",
       "      <th>buildingclasstypeid</th>\n",
       "      <th>buildingqualitytypeid</th>\n",
       "      <th>calculatedbathnbr</th>\n",
       "      <th>...</th>\n",
       "      <th>taxamount</th>\n",
       "      <th>taxdelinquencyyear</th>\n",
       "      <th>censustractandblock</th>\n",
       "      <th>logerror</th>\n",
       "      <th>Hot_Tub_or_Spa</th>\n",
       "      <th>County_Land_use_Code</th>\n",
       "      <th>Zoning_desc</th>\n",
       "      <th>Fireplace_flag</th>\n",
       "      <th>Tax_Delinquency</th>\n",
       "      <th>Transaction_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10754147</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10759547</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10843547</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>20800.37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>10859147</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>14557.57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10879947</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5725.17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  parcelid  airconditioningtypeid  architecturalstyletypeid  \\\n",
       "0           0  10754147                    NaN                       NaN   \n",
       "1           1  10759547                    NaN                       NaN   \n",
       "2           2  10843547                    NaN                       NaN   \n",
       "3           3  10859147                    NaN                       NaN   \n",
       "4           4  10879947                    NaN                       NaN   \n",
       "\n",
       "   basementsqft  bathroomcnt  bedroomcnt  buildingclasstypeid  \\\n",
       "0           NaN          0.0         0.0                  NaN   \n",
       "1           NaN          0.0         0.0                  NaN   \n",
       "2           NaN          0.0         0.0                  NaN   \n",
       "3           NaN          0.0         0.0                  3.0   \n",
       "4           NaN          0.0         0.0                  4.0   \n",
       "\n",
       "   buildingqualitytypeid  calculatedbathnbr        ...         taxamount  \\\n",
       "0                    NaN                NaN        ...               NaN   \n",
       "1                    NaN                NaN        ...               NaN   \n",
       "2                    NaN                NaN        ...          20800.37   \n",
       "3                    7.0                NaN        ...          14557.57   \n",
       "4                    NaN                NaN        ...           5725.17   \n",
       "\n",
       "   taxdelinquencyyear  censustractandblock  logerror  Hot_Tub_or_Spa  \\\n",
       "0                 NaN                  NaN       NaN              -1   \n",
       "1                 NaN                  NaN       NaN              -1   \n",
       "2                 NaN                  NaN       NaN              -1   \n",
       "3                 NaN                  NaN       NaN              -1   \n",
       "4                 NaN                  NaN       NaN              -1   \n",
       "\n",
       "   County_Land_use_Code  Zoning_desc  Fireplace_flag  Tax_Delinquency  \\\n",
       "0                     0           -1              -1               -1   \n",
       "1                     1            0              -1               -1   \n",
       "2                     2            1              -1               -1   \n",
       "3                     2            1              -1               -1   \n",
       "4                     3            2              -1               -1   \n",
       "\n",
       "   Transaction_date  \n",
       "0               NaT  \n",
       "1               NaT  \n",
       "2               NaT  \n",
       "3               NaT  \n",
       "4               NaT  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df['Hot_Tub_or_Spa'] = bool_to_int(combined_df,'hashottuborspa')\n",
    "combined_df['County_Land_use_Code'] = str_to_intcat(combined_df,'propertycountylandusecode')\n",
    "combined_df['Zoning_desc'] = str_to_intcat(combined_df,'propertyzoningdesc')\n",
    "combined_df['Fireplace_flag'] = bool_to_int(combined_df,'fireplaceflag')\n",
    "combined_df['Tax_Delinquency'] = bool_to_int(combined_df,'taxdelinquencyflag')\n",
    "combined_df['Transaction_date'] = to_datetime(combined_df, 'transactiondate')\n",
    "\n",
    "columns_to_drop = ['hashottuborspa', 'propertycountylandusecode','propertyzoningdesc',\n",
    "                  'fireplaceflag', 'taxdelinquencyflag','transactiondate']\n",
    "\n",
    "cleaned_df = combined_df.drop(columns_to_drop, 1)\n",
    "cleaned_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To wrap up this notebook I want to note a number of cleaning techniques I have not yet done.\n",
    "\n",
    "The first is that there are a number columns are nearly empty, which normally I would drop. However, I dont want to do any cleaning that I wouldnt do full data set yet and I do not know which columns are mostly empty on the full data set yet.\n",
    "\n",
    "The other is a number of statistical cleaning. I would normally try to estimate some of the empty values. Another technique I will try to do at a later date is find out which columns correlate most strongly to the goal which is 'logerror.' Another thing I might try to bin some of the continuous data or some of the larger categories. However, since this update is before the statistics section I will hold off on that for now.\n",
    "\n",
    "I also want to try using Gamma statistics with the continuous data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
